{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ae9d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='chatcmpl-BZgkS9g5fmfDWr6abBzaXKbabTYAL', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=0, id='call_Dcuer5y2RowXl7Ig47gCS9Ft', function=ChoiceDeltaToolCallFunction(arguments='', name='get_current_weather'), type='function')]), finish_reason=None, index=0, logprobs=None)], created=1747845504, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_76544d79cb', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-BZgkS9g5fmfDWr6abBzaXKbabTYAL', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='{\"', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1747845504, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_76544d79cb', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-BZgkS9g5fmfDWr6abBzaXKbabTYAL', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='location', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1747845504, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_76544d79cb', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-BZgkS9g5fmfDWr6abBzaXKbabTYAL', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='\":\"', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1747845504, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_76544d79cb', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-BZgkS9g5fmfDWr6abBzaXKbabTYAL', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='Paris', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1747845504, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_76544d79cb', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-BZgkS9g5fmfDWr6abBzaXKbabTYAL', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='\",\"', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1747845504, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_76544d79cb', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-BZgkS9g5fmfDWr6abBzaXKbabTYAL', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='unit', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1747845504, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_76544d79cb', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-BZgkS9g5fmfDWr6abBzaXKbabTYAL', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='\":\"', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1747845504, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_76544d79cb', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-BZgkS9g5fmfDWr6abBzaXKbabTYAL', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='c', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1747845504, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_76544d79cb', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-BZgkS9g5fmfDWr6abBzaXKbabTYAL', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='elsius', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1747845504, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_76544d79cb', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-BZgkS9g5fmfDWr6abBzaXKbabTYAL', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='\"}', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1747845504, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_76544d79cb', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-BZgkS9g5fmfDWr6abBzaXKbabTYAL', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='tool_calls', index=0, logprobs=None)], created=1747845504, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_76544d79cb', usage=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Hard-coded 'fake' weather API, in a real situation, this would be a real weather api, or anything else.\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    print(f\"PRINT STATEMENT: Getting weather for {location} with unit {unit}\") #Clairfication that the function actually is running and the model isn't making stuff up.\n",
    "    print() # empty print statement to add space and seperate from API response\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"32\", \"unit\": unit})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "    \n",
    "def run_conversation():\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"The weather in Paris\"\n",
    "    }]\n",
    "\n",
    "    # We define the tool array here instead of within the API call because it's just eaiser to look at and manage, just like with messages up there ^.\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g., San Francisco, CA\"},\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"], \"description\": \"The unit of measurement for the temperature\", \"default\": \"fahrenheit\"}\n",
    "                    },\n",
    "                    \"required\": [\"location\"]\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", # the model you wanna use, if this doesn't work, try using \"gpt-3.5-turbo-0125\"\n",
    "        messages=messages, # define the context, ususally this would be a thing that isn't static\n",
    "        tools=tools, # the array of tools we defined up there ^\n",
    "        tool_choice=\"auto\", # pretty sure this is default, so you don't need it, but it's here just in case.\n",
    "        stream=True, # enable streaming for the API\n",
    "    )\n",
    "\n",
    "    # This is where we print the chunks directly from the API if no function was called from the model\n",
    "    for chunk in stream:\n",
    "        print(chunk)\n",
    "\n",
    "\n",
    "run_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852777b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
