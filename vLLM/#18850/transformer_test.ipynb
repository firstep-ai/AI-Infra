{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7ed628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068e4e2048e7451096f5389b7d3448b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/478 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wangz\\.cache\\huggingface\\hub\\models--ByteDance--Dolphin. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5199ae126e05446eb714dbf11219b021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/4.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1dee954c73248d3ad91cfc9306fec0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.86M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1e05255ac34d2aa73986dd29125992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/277 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eadf317c6034ab29f1585d0c1f4ba78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.85k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec256bf6073c4aceab975a1392c84219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/796M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa7832e78e54a5eb73a4ac028171802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f121f2d3b14a46abd819c2fb16fb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wangz\\.cache\\huggingface\\hub\\datasets--hf-internal-testing--example-documents. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d816b638643742e2b48526df1870c72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)-00000-of-00001-cca0db7e388ce4bc.parquet:   0%|          | 0.00/2.86M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da1933576a94297b88462b01a835126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s_docvqa><s_question>What time is the coffee break?</s_question><s_answer>_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# pip install datasets\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"ByteDance/Dolphin\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\"ByteDance/Dolphin\")\n",
    "\n",
    "dataset = load_dataset(\"hf-internal-testing/example-documents\", split=\"test\")\n",
    "image = dataset[0][\"image\"]\n",
    "question = \"What time is the coffee break?\"\n",
    "task_prompt = f\"<s>Parse the reading order of this document. <Answer/>\"\n",
    "inputs = processor(image, task_prompt, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    pixel_values=inputs.pixel_values,\n",
    "    max_length=512\n",
    ")\n",
    "answer = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8caeb81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse the reading order of this document. [0.31,0.06,0.51,0.07] para[0.31,0.07,0.67,0.15] para[0.31,0.17,0.68,0.19] para[0.41,0.19,0.61,0.23] para[0.31,0.26,0.61,0.27] para[0.31,0.28,0.67,0.31] para[0.31,0.34,0.67,0.37] para[0.31,0.38,0.66,0.41] para[0.43,0.41,0.68,0.50] para[0.41,0.51,0.68,0.69] para[0.31,0.71,0.59,0.73] para[0.31,0.73,0.39,0.75] para[0.41,0.77,0.53,0.78] para[0.31,0.77,0.68,0.80] para[0.31,0.82,0.61,0.84] para[0.31,0.84,0.68,0.88] para[0.56,0.86,0.68,0.88] para\n"
     ]
    }
   ],
   "source": [
    "task_prompt = f\"<s>Parse the reading order of this document. <Answer/>\"\n",
    "inputs = processor(image, task_prompt, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    pixel_values=inputs.pixel_values,\n",
    "    max_length=512\n",
    ")\n",
    "answer = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a31f338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse the table in the image. 11:14 to 11:39 a.m.Coffee Break11:39 a.m.Coffee will be served for men and women in the lobby adjacent to exhibit area. Please move into exhibit area. (Exhibits Open)11:39 a.m.TRRF GENERAL SESSION (PART I)11:39 a.m.Presiding: Lee A. Waller TRRF Vice President11:39 to 11:44 a.m.Introductory Remarks 11:44 a.m.11:44 a.m.Lee A. Waller, TRRF Vice Presi- dent11:44 a.m. to 12:25 p.m.Individual Interviews with TRRF Public Board Members and Sci-entific Advisory Council Mem-bers12:25 p.m.Conducted by TRRF Treasurer Philip G. Kuehn to get answers which the public refrigerated warehousing industry is looking for. Plus questions from the floor. Dr. Emil M. Mrak, University of Cal-ifornia, Chairman, TRRF Board; Sam R. Cecil, University of Georgia College of Agriculture; Dr. Stanley Charm, Tufts University School of Medicine; Dr. Robert H. Cotton, ITT Continental Baking Company; Dr. Owen Fennema, University of Wis-consin; Dr. Robert E. Hardenburg, USDA.12:25 to 12:58 p.m.Questions and Answers12:58 to 12:58 to 12:58 to 12:60 p.m.Exhibits Open Capt. Jack Stoney Room12:00 to 12:00 p.m.TRRF Scientific Advisory Council Meeting12:00RTRF Scientific Advisory Council Meeting\n"
     ]
    }
   ],
   "source": [
    "task_prompt = f\"<s>Parse the table in the image. <Answer/>\"\n",
    "inputs = processor(image, task_prompt, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    pixel_values=inputs.pixel_values,\n",
    "    max_length=512\n",
    ")\n",
    "answer = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923751a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
